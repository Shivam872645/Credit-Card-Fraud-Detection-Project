# -*- coding: utf-8 -*-
"""Untitled18.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O1SxwQYdi4Vh7O-J20TH6DTRD518QoEF
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import warnings

credit_card=pd.read_csv('creditcard.csv')

credit_card.head()

"""# Exploratory Data Analysis"""

rows,columns=credit_card.shape
print(f"Number of rows: {rows}")
print(f"Number of columns: {columns}")

credit_card.head()

credit_card.tail()

credit_card.info()

credit_card.isnull().sum()

from sklearn.preprocessing import StandardScaler # Using for scaling the datasets

sc = StandardScaler()
credit_card['Amount']=sc.fit_transform(pd.DataFrame(credit_card['Amount']))

credit_card.head()

credit_card = credit_card.drop(['Time'],axis=1)

credit_card.head()

credit_card.shape

credit_card.duplicated().sum()

credit_card.duplicated().any()

# Now Removing these duplicates
credit_card_new=credit_card.drop_duplicates()
credit_card_new.shape

credit_card_new.head()

credit_card_new.columns

credit_card_new.duplicated().any()

credit_card_new['Class'].value_counts()

credit_card_new['Class'].value_counts().plot(kind='bar')

# Separate the data
legitimate = credit_card_new[credit_card_new['Class'] == 0]
fraud = credit_card_new[credit_card_new['Class'] == 1]

# Shapes
print("Legitimate shape:", legitimate.shape)
print("Fraud shape:", fraud.shape)

# Correct counting
legitimate_count, fraud_count = credit_card_new['Class'].value_counts().sort_index()

print(f"Legitimate transactions (0): {legitimate_count}")
print(f"Fraud transactions (1): {fraud_count}")
print("This is imbalanced data")

275190/275663

473/275663

credit_card_new.describe()

"""# Handling Imbalanced Dataset"""

X=credit_card_new.drop('Class',axis=1)
Y=credit_card_new['Class']

X.shape

Y.shape

from imblearn.over_sampling import SMOTE

smote=SMOTE(random_state=42)
x_smote,y_smote=smote.fit_resample(X,Y)

x_smote.shape

y_smote.shape

y_smote.value_counts()

from collections import Counter

print('Original dataset shape', Counter(Y))
print('Resample dataset shape',Counter(y_smote))

"""# Data Visualization"""

legitimate['Amount'].plot(kind='hist')

fraud['Amount'].plot(kind='hist')

fraud['Amount'].plot(kind='box')

legitimate['Amount'].plot(kind='box')

# now correlation marix in imbalanced data

corr_imbalanced=credit_card.corr()
corr_imbalanced

corr_imbalanced=credit_card_new.corr()
plt.figure(figsize=(8,6))
sns.heatmap(corr_imbalanced,annot=False,cmap="plasma",linewidth=0.5)
plt.title("Correlation Matrix for Imbalanced Data")
plt.show()

# Now for balanced data
corr_balanced=x_smote.corr()
plt.figure(figsize=(8,6))
sns.heatmap(corr_balanced,annot=False,cmap="plasma",linewidth=0.5)
plt.title("Correlation Matrix for balanced Data")
plt.show()

custom_palette=sns.color_palette(["blue","gold"])
plt.figure(figsize=(8,6))
sns.countplot(x="Class",data=credit_card_new,palette=custom_palette)
plt.title("Class Distribution")
plt.show()

custom_palette=sns.color_palette(["blue","gold"])
plt.figure(figsize=(8,6))
sns.countplot(x=y_smote,palette=custom_palette)
plt.title("Distribution of Classes After Resampling (SMOTE)")
plt.xlabel("Class (0: Fraud,1: Legitimate)")
plt.ylabel("Count")
plt.show()



"""# Handling Imbalanced Dataset
- UnderSampling
"""

legitimate = credit_card_new[credit_card_new['Class'] == 0]
fraud = credit_card_new[credit_card_new['Class'] == 1]


print("Legitimate shape:", legitimate.shape)
print("Fraud shape:", fraud.shape)

legitimate_sample=legitimate.sample(n=473)

legitimate_sample.shape

new_data = pd.concat([legitimate_sample,fraud],ignore_index=True)

new_data['Class'].value_counts()

new_data.head()

X = new_data.drop('Class',axis=1)
y = new_data['Class']

"""# Training the Model ( Undersampling)"""

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20,
                                                 random_state=42)

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Evaluation function
def evaluate_model(y_true, y_pred):
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred)
    recall = recall_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)
    return accuracy, precision, recall, f1

test_accuracy = []
model_names = []

## Beginning Model Training
models = {
    "Logistic Regressor": LogisticRegression(),

    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest Regressor":RandomForestClassifier(),


}

for i in range(len(list(models))):
    model = list(models.values())[i]
    model.fit(X_train, y_train) # Train model

    # Make predictions
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)

    # Evaluate Train and Test dataset
    accuracy_train_score , precision_train_score, recall_train_score,f1_train_score = evaluate_model(y_train, y_train_pred)

    accuracy_test_score , precision_test_score, recall_test_score,f1_test_score = evaluate_model(y_test, y_test_pred)

   # store values for plotting
    test_accuracy.append(accuracy_test_score * 100)
    model_names.append(list(models.keys())[i])



    print(list(models.keys())[i])

    print('Model Score for Training set')
    print("- accuracy_score: {:.4f}".format( accuracy_train_score ))
    print("- precision_score: {:.4f}".format(precision_train_score))
    print("- recall_score: {:.4f}".format( recall_train_score))
    print("- recall_score: {:.4f}".format( f1_train_score))


    print('----------------------------------')
    print('Model Score for Test set')
    print("- accuracy_score: {:.4f}".format( accuracy_test_score ))
    print("- precision_score: {:.4f}".format(precision_test_score))
    print("- recall_score: {:.4f}".format( recall_test_score))
    print("- recall_score: {:.4f}".format( f1_test_score))
    print('='*35)
    print('\n')

final_data = pd.DataFrame({
    'Models': model_names,
    'Accuracy': test_accuracy
})

final_data

plt.figure(figsize=(6, 5))
ax = sns.barplot(x=final_data['Models'], y=final_data['Accuracy'], palette=['blue', 'green', 'red'])

for i, v in enumerate(final_data['Accuracy']):
    ax.text(i, v + 1, f"{v:.2f}%", ha='center')

plt.xlabel('Models')
plt.ylabel('Accuracy (%)')
#plt.title('Accuracy Score of Models')
plt.xticks(rotation=40)
plt.ylim(0, 100)
plt.show()

"""# Oversampling"""

X=credit_card_new.drop('Class',axis=1)
Y=credit_card_new['Class']

X.shape

Y.shape

X_res,y_res = SMOTE().fit_resample(X,Y)

y_res.value_counts()

"""# Training the Model (Oversampling)"""

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X_res,y_res,test_size=0.20,
                                                 random_state=42)

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Evaluation function
def evaluate_model(y_true, y_pred):
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred)
    recall = recall_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)
    return accuracy, precision, recall, f1

test_accuracy1 = []
model_names1 = []

## Beginning Model Training
models = {
    "Logistic Regressor": LogisticRegression(),

    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest Regressor":RandomForestClassifier(),


}

for i in range(len(list(models))):
    model = list(models.values())[i]
    model.fit(X_train, y_train) # Train model

    # Make predictions
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)

    # Evaluate Train and Test dataset
    accuracy_train_score , precision_train_score, recall_train_score,f1_train_score = evaluate_model(y_train, y_train_pred)

    accuracy_test_score , precision_test_score, recall_test_score,f1_test_score = evaluate_model(y_test, y_test_pred)

   # store values for plotting
    test_accuracy1.append(accuracy_test_score * 100)
    model_names1.append(list(models.keys())[i])



    print(list(models.keys())[i])

    print('Model Score for Training set')
    print("- accuracy_score: {:.4f}".format( accuracy_train_score ))
    print("- precision_score: {:.4f}".format(precision_train_score))
    print("- recall_score: {:.4f}".format( recall_train_score))
    print("- recall_score: {:.4f}".format( f1_train_score))


    print('----------------------------------')
    print('Model Score for Test set')
    print("- accuracy_score: {:.4f}".format( accuracy_test_score ))
    print("- precision_score: {:.4f}".format(precision_test_score))
    print("- recall_score: {:.4f}".format( recall_test_score))
    print("- recall_score: {:.4f}".format( f1_test_score))
    print('='*35)
    print('\n')

final_data1 = pd.DataFrame({
    'Models': model_names1,
    'Accuracy': test_accuracy1
})

final_data1

plt.figure(figsize=(6, 5))
ax = sns.barplot(x=final_data1['Models'], y=final_data1['Accuracy'], palette=['blue', 'green', 'red'])

for i, v in enumerate(final_data1['Accuracy']):
    ax.text(i, v + 1, f"{v:.2f}%", ha='center')

plt.xlabel('Models')
plt.ylabel('Accuracy (%)')
#plt.title('Accuracy Score of Models')
plt.xticks(rotation=40)
plt.ylim(0, 100)
plt.show()

















